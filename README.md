# Q3-Sapien-Robotics
(A) Model Selection and Architectural Choice for PCB Inspection VLM

For the given industrial PCB inspection scenario, using a generic end-to-end vision–language model such as LLaVA, BLIP-2, or Qwen-VL is not optimal due to their large size, high inference latency, weak spatial grounding, and tendency to hallucinate in domain-specific settings. Since the system must operate fully offline, deliver results in under two seconds, and provide precise defect localization, a custom lightweight VLM architecture is the most suitable choice. The proposed solution uses a detector-first design, where a high-accuracy object detection model such as YOLOv8 or RT-DETR serves as the vision encoder, and a small language model (around 1.5B–3B parameters) acts as the language decoder. This choice is driven by factors such as fast inference speed, strong localization ability, ease of fine-tuning with limited supervision, and permissive licensing. Architectural modifications are necessary to ensure precise localization, including replacing global image embeddings with region-level defect tokens and enforcing strict visual grounding so that all language outputs are conditioned on detected bounding boxes.

(B) Custom Vision–Language Architecture Design for PCB-Specific Requirements

The VLM architecture is designed specifically to meet PCB inspection requirements, where defects are small, localized, and safety-critical. The vision encoder is a fine-tuned object detector trained on the available PCB dataset to accurately identify defect types, bounding box coordinates, and confidence scores. Instead of passing dense image embeddings to the language model, each detected defect is converted into a structured region token that includes spatial information and semantic metadata. These tokens are then passed to the language decoder through a controlled fusion mechanism, ensuring that the model reasons only over detected defects. The language decoder’s role is not to interpret raw images, but to translate structured visual evidence into natural language responses and machine-readable outputs. This separation of responsibilities ensures high precision, interpretability, and robustness, which are essential for industrial quality inspection systems.

(C) Model Optimization Strategies for Low-Latency Offline Inference

To meet the strict requirement of sub-2-second inference in an offline environment, the VLM is heavily optimized at both the model and system levels. Quantization techniques such as INT8 or INT4 are applied to both the vision encoder and language decoder to reduce memory usage and computational overhead. Parameter-efficient fine-tuning methods like LoRA are used to adapt the language model to the PCB domain without increasing inference cost. Additionally, pruning redundant attention heads and using optimized inference runtimes such as TensorRT or ONNX further reduce latency. Knowledge distillation is also employed, where a larger teacher model transfers task-specific knowledge to the smaller VLM, preserving accuracy while improving speed. These combined optimizations ensure fast, reliable performance on edge or on-premise hardware.

(D) Hallucination Mitigation Techniques in Industrial Vision–Language Models

Reducing hallucinations is critical in industrial inspection systems, as false defect reports can lead to unnecessary rework or missed failures. Hallucination mitigation is addressed both architecturally and during training. Architecturally, the language model is prevented from accessing raw image embeddings or generating free-form descriptions; instead, it can only attend to region tokens derived from the detector’s outputs. This enforces strict visual grounding and ensures that every claim made by the model corresponds to an actual detected defect. During training, negative sampling is used by generating questions about defects that are not present in the image, teaching the model to respond with “no defect detected” and low confidence. A confidence-aware loss function penalizes high-confidence incorrect predictions, improving calibration. At inference time, confidence thresholding and abstention mechanisms further reduce false positives by allowing the model to explicitly indicate uncertainty.

(E) Multi-Stage Training Strategy and Synthetic QA Generation

The training process follows a structured multi-stage approach to compensate for the lack of annotated QA pairs. In the first stage, the vision encoder is trained independently on the PCB dataset using bounding box supervision to achieve high defect detection and localization accuracy. In the second stage, synthetic question–answer pairs are automatically generated from the bounding box annotations using deterministic templates, such as counting defects, querying defects in specific regions of the PCB, or checking the presence or absence of certain defect types. Since the answers are directly derived from ground-truth annotations, this process introduces no hallucination noise. In the third stage, the language model is instruction-tuned using these synthetic QA pairs while keeping the vision encoder frozen, aligning natural language queries with structured visual inputs. Finally, robustness is improved using data augmentation techniques such as noise injection, lighting variation, blur, and partial occlusion to simulate real-world inspection conditions.
<img width="961" height="1138" alt="image" src="https://github.com/user-attachments/assets/b66dd5cd-cbfc-470e-a6b1-5b540d5b18dd" />

(F) Validation and Evaluation Methodology for Accuracy and Reliability

Validation of the proposed VLM system is performed using multiple task-specific metrics to ensure reliability and safety. Localization accuracy is evaluated using Intersection-over-Union thresholds and center-point error to assess bounding box precision. Counting accuracy is measured using absolute count error and exact match rates between predicted and ground-truth defect counts. Hallucination is explicitly evaluated by measuring the false positive rate on defect-free PCBs and the rate of unsupported claims, where the model reports defects not detected by the vision encoder. Confidence calibration metrics such as Expected Calibration Error are used to assess the reliability of confidence scores. Finally, end-to-end latency is measured on the target deployment hardware to verify that the system consistently meets the sub-2-second inference requirement under real operating conditions.



